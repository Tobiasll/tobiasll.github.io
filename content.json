{"meta":{"title":"Tobias","subtitle":"subtitleTest","description":"一名计算机小白，JAVA新手的个人博客","author":"tobias","url":"http://tobiasll.github.io","root":"/"},"pages":[{"title":"自我介绍","date":"2019-09-26T04:44:20.000Z","updated":"2019-09-26T04:48:52.885Z","comments":true,"path":"about/index.html","permalink":"http://tobiasll.github.io/about/index.html","excerpt":"","text":"自我介绍测试"}],"posts":[{"title":"二叉树DFS、BFS、Morris遍历","slug":"二叉树DFS、BFS、Morris遍历","date":"2019-11-26T06:46:16.000Z","updated":"2019-11-27T06:26:55.272Z","comments":true,"path":"2019/11/26/二叉树DFS、BFS、Morris遍历/","link":"","permalink":"http://tobiasll.github.io/2019/11/26/二叉树DFS、BFS、Morris遍历/","excerpt":"","text":"序言最近一个月时间都在集中刷leetcode的树部分的题目，发现解法普遍都可以用二叉树的各种遍历来解题，而且一道题有很多种解法。 我们在学习深度优先遍历和广度优先遍历时就知道，这两种遍历可以用在图和树中，其中树的DFS（深度优先遍历）分为前序、中序和后序三种，这三种方式可以用递归的方式或者用栈来迭代，也可以使用Morris算法来实现。 而BFS（广度优先遍历，相对简单很多）迭代整个树并用一个队列配合即可实现层级遍历 DFS深度优先遍历，顾名思义，就是优先遍历整个树的深度，然后再遍历完整个树 深度优先遍历需要不断的往下递归遍历，而递归又涉及出栈和入栈的过程，所以三种DFS迭代的方式遍历我们都会使用一个Stack来模拟出栈和入栈的过程 分别可以用递归和迭代已经Morris算法来实现，Morris我们将放到最后再一起讲 前序遍历顾名思义就是先打印或检查当前节点，再不断的遍历左子树和右子树 如图所示，从根节点不断的遍历左边直到叶子节点，然后再遍历右边，那么输出就是10-&gt;5-&gt;4-&gt;8-&gt;19-&gt;13-&gt;24 递归写法那么上面说了是先打印当前节点再不断遍历左节点压栈，然后不断出栈，再遍历当前节点的右节点树，那么代码就很简单了 12345678910public void preOrderTraversalByRecursive(TreeNode root) &#123; if (root != null) &#123; // 打印当前节点 System.out.println(this.root.val); // 递归左节点 preOrderTraversalByRecursive(root.left); // 递归右节点 preOrderTraversalByRecursive(root.right); &#125; &#125; 迭代写法前面讲到需要不断的入栈和出栈，所以我们需要借助一个Stack来实现这个过程，先序遍历的迭代写法有两种，分别有两种特性。第一种会丢失掉右孩子，而第二种不会丢失 第一种，丢失右节点因为不断的先将左孩子入栈，所以会丢失右孩子 123456789101112131415161718192021222324public void preOrderTraversalByIteratorWithLossRightNode(TreeNode root) &#123; if (root == null) &#123; return; &#125; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); while (root != null || !stack.isEmpty()) &#123; if (root != null) &#123; // 拿到当前节点，打印节点的值 System.out.println(root.val); // 不断的入栈 stack.push(root); // 将当前节点的左节点赋值为当前节点，不断的将左节点入栈 root = root.left; &#125; else &#123; // 到达最左叶子节点，出栈然后将出栈节点的右节点赋值为当前节点 // 例如：叶子节点为4：root = pop.right = null // 因为root = null,下一次还是继续出栈，这时候pop = 5，root = pop.right = 8，这时候8会被打印然后入栈并不断的遍历左节点 TreeNode pop = stack.pop(); root = pop.right; &#125; &#125; &#125; 第二种，不丢失右节点因为第一种是先不断的压栈左节点，没有保存右节点，导致的右节点丢失，所以第二种我们就可以提前将右孩子保存到栈中，就可以保证右节点不丢失了，同时利用栈的后入先出的特性就可以将右节点给压到栈底部 12345678910111213141516171819202122232425public void preOrderTraversalByIteratorWithDoNotLoseRightNode(TreeNode root) &#123; if (root == null) &#123; return; &#125; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); // 将根节点压栈 stack.push(root); while (!stack.isEmpty()) &#123; // 不断的出栈，栈的变化 第一次循环 10 ，然后出栈后栈为空，然后右和左节点压栈，栈：19，5， // 第二次 5 出栈，栈：19，然后再将右左入栈，栈：19，8，4 // 第三次 4 出栈，栈：19， 8， 第四次 8 出栈， 栈：19 // 第五次 19 出栈， 栈为空，然后24，13入栈，然后13和24在依次出栈 TreeNode pop = stack.pop(); // 打印出栈的当前节点 System.out.println(pop.val); // 将出栈节点的右节点压栈 if (pop.right != null) &#123; stack.push(pop.right); &#125; // 将左节点压栈 if (pop.left != null) &#123; stack.push(pop.left); &#125; &#125; &#125; 两种遍历在leetcode的应用leetcode有一道题是将一个二叉树变成一条链表形式的二叉树114. Flatten Binary Tree to Linked List 因为第一种遍历会丢失右节点，所以我们需要不断的找出左子树最右边的节点一遍把右节点接过来 过程如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950511.将左子树插入到右子树的地方2.将原来的右子树接到左子树的最右边节点3.考虑新的右子树的根节点，一直重复上边的过程，直到新的右子树为 null 1 / \\ 2 5 / \\ \\3 4 6//将 1 的左子树插入到右子树的地方 1 \\ 2 5 / \\ \\ 3 4 6 //将原来的右子树接到左子树的最右边节点 1 \\ 2 / \\ 3 4 \\ 5 \\ 6 //将 2 的左子树插入到右子树的地方 1 \\ 2 \\ 3 4 \\ 5 \\ 6 //将原来的右子树接到左子树的最右边节点 1 \\ 2 \\ 3 \\ 4 \\ 5 \\ 6 ...... 代码 123456789101112131415161718192021public void flatten(TreeNode root) &#123; while (root != null) &#123; //左子树为 null，直接考虑下一个节点 if (root.left == null) &#123; root = root.right; &#125; else &#123; // 找左子树最右边的节点 TreeNode pre = root.left; while (pre.right != null) &#123; pre = pre.right; &#125; //将原来的右子树接到左子树的最右边节点 pre.right = root.right; // 将左子树插入到右子树的地方 root.right = root.left; root.left = null; // 考虑下一个节点 root = root.right; &#125; &#125;&#125; 第二种 我们用栈保存了右孩子，所以不需要担心右孩子丢失了。用一个 pre 变量保存上次遍历的节点 过程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869 root last = null stack=TreeNode(1) 1 / \\ 2 5 / \\ \\3 4 6将根节点出栈 pop last = null stack = &#123;5 | 2 &#125; 1 \\ | / \\ / \\ 6 | 3 4 2 5 / \\ \\3 4 6然后将last = pop下一次循环pop last stack = &#123;5 | 4 | 3&#125; 2 1 \\ | / \\ / \\ 6 | 3 4 2 5 / \\ \\ 3 4 6这时候last不等于空了将last的右边等于出栈节点然后断掉左节点last1 \\ 2 / \\3 4将pop赋值给last,移动到2节点pop last stack = &#123;5 | 4&#125;3 2 \\ / \\ 6 3 4然后pop赋值给last的右节点同时断开左节点last1 \\ 2 \\ 3然后将pop赋值给last,移动到3节点，依次类推pop last stack = 54 3 6last1 \\ 2 \\ 3 \\ 4pop last stack = 6 5 4 6last1 \\ 2 \\ 3 \\ 4 \\ 5 6就这样不断的先序遍历来将出栈的节点赋值给last的右节点，同时不断的断开左节点，利用不会丢失右节点的先序遍历方式来实现 代码 123456789101112131415161718192021222324252627public void flatten(TreeNode root) &#123; if (root == null) &#123; return null; &#125; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); // 将根节点入栈 stack.push(root); // 初始化上一个节点 TreeNode last = null; while (!stack.isEmpty()) &#123; TreeNode pop = stack.pop(); if(last != null)&#123; // 将上一个节点的右节点赋值为当前出栈节点，并且断开左边的节点 last.right = pop; last.left = null; &#125; if (pop.right != null) &#123; stack.push(pop.right); &#125; if (pop.left != null) &#123; stack.push(pop.left); &#125; // 将当前节点赋值给last last = pop; &#125; &#125; 中序遍历顾名思义就是先遍历左子树，然后检查当前节点值或打印输出，最后遍历右子树 由于二叉树定义，当前节点的左节点的值小于当前节点，右节点大于当前节点的问题，所以中序遍历会打印出从小打到右顺序的值。 在中序应用方面，通常我们可以利用这个特性来判断一个树是否符合二叉树的左节点小于根节点，右节点大于根节点，以及我们可以利用中序输出的结果加上前序或者后序的结果来还原一个完整的树 先不断遍历左节点，直到最左边的叶子节点4，然后5出栈，再将5的右节点入栈，所以最后的结果是：4-&gt;5-&gt;8-&gt;10-&gt;13-&gt;19-&gt;24 递归写法12345678910public void inOrderTraversalByRecursive(TreeNode root) &#123; if (root != null) &#123; // 递归左节点 preOrderTraversalByRecursive(root.left); // 打印当前节点 System.out.println(this.root.val); // 递归右节点 preOrderTraversalByRecursive(root.right); &#125; &#125; 迭代写法还是一样借助栈来实现 12","categories":[],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://tobiasll.github.io/tags/数据结构与算法/"}]},{"title":"MySQL学习笔记—_逻辑架构和简介","slug":"MySQL学习笔记—-逻辑架构和简介","date":"2019-10-31T03:40:11.000Z","updated":"2019-10-31T09:49:48.371Z","comments":true,"path":"2019/10/31/MySQL学习笔记—-逻辑架构和简介/","link":"","permalink":"http://tobiasll.github.io/2019/10/31/MySQL学习笔记—-逻辑架构和简介/","excerpt":"","text":"序言在构建系统时，我们都离不开对数据的存储和获取，而对于数据库的应用和设计应当是每个后端开放人员、架构师、DBA等等人员都需要去深入学习理解的基础知识（特别是构建数据密集型应用），最近在看 高性能 MySQL 第三版和MySQL 技术内幕，所以写一下笔记梳理一下知识，这两本书都比较偏上层，底层知识涉及并不太多，想了解更加底层的人推荐阅读一下数据库系统实现 (第 2 版)和数据库系统概念等书籍。 MySQL简介MySQL是一个单进程多线程支持并发处理的关系型数据库（不支持并行），并且支持跨平台，可移植，在各平台底层实现各有不同的情况下，基本上能够保证各平台上的物理体系结构的一致性，其灵活性、开源、高性能、跨平台等特点深受企业和开发人员的喜爱。 MySQL数据库实例在系统上表现为一个进程，实例启动时，按照/etc/my.cnf -&gt; /etc/mysql/my.cnf -&gt; /usr/local/mysql/etc/my.cnf -&gt; /root/my.cnf等顺序读取默认配置的参数来启动数据库实例，配置文件以最后一个中的参数为准。 数据库和实例：两个词有着不同的定义 数据库：物理操作系统文件和其他类型文件的 集合，文件可以是存放于内存之中的文件也可以是磁盘之中的 实例：MySQL数据库由后台线程和一个共享内存区域组成 数据库是文件的集合，数据库实例是处理用户请求并执行对应操作的一个程序，数据库实例才是真正用于操作数据库文件的。 MySQL实例逻辑架构 MySQL实例的逻辑架构大致分为3层： 第一层：里面的东西并不是MySQL所独有的，大多数基于网络的客服端/服务端的工具都有类似的架构 图中的1:客户端连接者们，如Linux中MySQL操作终端，java中的jdbc等等 2 ：连接池组件处理各个连接，授权认证，安全等等 3 : 管理服务和工具服务 第二层：核心层，包括解析、分析、优化、换成、以及所有的内置函数，所有跨存储引擎的功能都在这一次实现：存储过程、触发器、视图等等 SQL接口组件 5：查询分析器组件 6：优化器组件（执行计划生成，索引选择） 7：缓存组件 第三层：插拔式存储引擎和文件系统： 8：插拔式存储引擎 9：物理文件 注：以上模块归属那一层是大概分的，可能存在不准确情况 连接MySQL连接MySQL是一个客户端连接进程和MySQL实例进行通信的建立，MySQL不论在哪一种平台都提供了TCP/IP套接字的连接方式，当通过TCP/IP连接到实例时，MySQL会首先去判断该用户是否存在，密码是否正确，然后检查一张权限视图，是否有权限执行某些特定的操作等等。 每个客户端连接都会在MySQL实例进程中拥有一个线程，这个连接的查询都会在这个单独的线程中执行，实例会缓存这个线程，所以不需要为每一个新建的连接创建和销毁线程，但是MySQL默认如果客户端连接线程如果连续8小时都没对实例进行任何的操作会自动的销毁掉这个线程，关闭这个 长连接，等再次请求时则会抛出Lost connection to MySQL server during query。异常 使用线程池MySQL5.5以上允许线程池插件，可以使用池中少量的线程来服务大量的连接， 在面对有限的昂贵连接资源时，频繁的打开物理连接后就关闭，造成系统性能低下时，我们可以使用线程来避免，线程池是一个在程序启动时就建立足够的数据库连接，由一个池来管理这些连接的线程，当有请求时则从池中直接获取连接去操作数据库，执行完成后将连接重新放回连接池来达到连接的重用，避免消耗内存资源，并且当请求流量突增时或减少时，可以动态增加或减少池中的连接数，并拥有监控或者诊断等等功能 因为第一代连接池一般采用单线程同步的架构设计（例如 DBCP…），所以我们可以选择第二代采用了多线程模型的Druid，关于连接池包含了很多内容，在后续的章节再详细简介 MySQL的存储引擎从逻辑架构图中我们可以看到MySQL中的存储引擎是插拔式的，即我们可以根据需求选择对应的存储引擎，其中可以分为MySQL官方的和第三方提供的 InnoDB 存储引擎MySQL主推并且5.5.8之后默认和最常用的一款存储引擎，主要面向在线事务处理（OLTP Online transaction processing）的应用，支持行锁、外键、事务、并发版本控制、预读、二次写、插入缓冲、自适应哈希等等强大的功能，具备高可用、高性能、高拓展等特性，我们之后会都会围绕这个引擎来细讲这些内容 MyISAM 存储引擎MyISAM 是MySQL 5.5.8之前默认的存储引擎，主要面向在线分析处理 （OLAP Online analytical processing）的应用，不支持事务、表所、支持全文索引、不支持崩溃后的安全恢复、缓冲池只缓存索引文件，不缓存数据文件、采用赫夫曼编码静态算法（利用不同的字符内容编码加出现的频率组合来生成带权霍夫曼二叉树节约内存空间，出现频率越高在树中的层级越低，前缀编码越短）来压缩数据等特性，MyISAM 设计简单，数据以紧密格式存储，所以在某些场景下的性能很好（例如：只读场景） NDB存储引擎NDB是一个集群存储引擎，分布式的、share-nothing的、容灾的、高可用的数据库组合，其连接操作是在MySQL数据库层完成的，因此复杂的连接操作需要巨大的网络开销，查询速度也会变得很慢 Memory 存储引擎Memory 将表中的数据存放在内存中，所以重启时会导致数据丢失，适合用来存储临时数据的临时表和数据仓库的维度表，默认使用哈希索引，只支持表锁，所以并发性能不理想，存储变长字段时会按照定长字段的方式进行存储，因此也会浪费一定的内存，并且不支持BlOB和Text类型 Archive 存储引擎Archive 是用来高速插入和压缩功能的，只支持insert和select操作，使用zlib算法将数据行进行压缩后再存储，可以达到1:10的压缩比例，适合拿来存储归档数据（日志信息和数据采集类），使用行锁来提高并发操作，但是本身不是事务安全的，所以会存在一定的数据不一致问题 Federated 存储引擎Federated 是访问其他MySQL服务器的一个代理，会创建一个到远程MySQL服务器的客户端连接，并将查询传输到远程服务器执行，然后提取或者发送需要的数据，不支持异构数据库表 Maria 存储引擎Maria 可以看作MyISAM的后续版本，支持缓存数据和所以文件，行锁设计，提供并发版本控制、支持事务和非事务等安全选项、更好的BlOB字符类型处理的功能 其他存储引擎除了上面的7种还有许多存储引擎，包括第三方的，有OLTP类、OLAP类、面向列的、社区提供的种种存储引擎，这些存储引擎加起来的数量非常多 存储引擎的选择 MySQL官方手册提供了一些常用的存储引擎直接的不同之处的对比，包括存储容量的限制、事务支持、锁的粒度等等，见上图 大部分情况下，InnoDB都是正确的选择，除非需要用到某些InnoDB不具备的特性，并且没有其他的办法可以替代，否则都应该优先选择InnoDB引擎。除非万不得已，否则建议不要混合使用多种不同的存储引擎，可能会带来一系列的复杂的问题，以及一些潜在的bug和边界问题 选择不同的存储引擎是，应考虑的因素： 事务支持：需要则选择InnoDB，不需要且都是select和insert操作则采用MyISAM（日志型应用） 备份支持：需要在线热备份选择InnoDB是基本的要求 崩溃恢复：相对而言MyISAM崩溃后发生损坏的概率比InnoDB要高很多，而且恢复的速度也要慢 特有的特性：如果一个存储引擎拥有一些关键的特性，同时又缺乏一些必要的特性，那么有时候不得不做折中的考虑，或者在架构设计上做一些取舍 日志型应用这一类有着高要求的插入速度，数据库不能成为瓶颈，MyISAM或者Archive存储引擎对这类应用比较合适，因为他们开销低，而且插入速度非常块 只读或者大部分情况都只读的表典型的读多写少的业务，如果不介意MyISAM崩溃恢复的问题，选用MyISAM存储引擎是比较合适的，否则还是建议采用InnoDB，在很多场景下，InnoDb的速度都比MyISAM快，特别是使用聚集索引或者将需要的数据放到内存中的情况下 MyISAM随着应用压力的上升，可能会迅速的恶化，导致各种锁竞争、数据丢失、崩溃等问题 订单处理需要选择有事务的存在引擎，并且可能需要支持外键，InnoDB是最合适的选择 大数据量数据太大的话，则需要建立数据仓库，Infobright是MySQL数据仓库最成功的解决方案，如果不适合则可以使用TokuDB，或者采用InnoDB，不过就需要进行例如分库分表，数据分片等处理 小结这里简单的解释了一些MySQL，通篇文章并没有讲关于底层的实现，都是大致的做个介绍，特别是MySQL核心层还有存储引擎层都忽略了，所以接下来都会用多个专题来总结这些原理，详细解释 参考内容《高性能MySQL 第三版》 《MySQL 技术内幕》","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://tobiasll.github.io/tags/MySQL/"}]},{"title":"java 内存结构","slug":"java 内存结构","date":"2019-10-07T07:01:25.000Z","updated":"2019-10-31T03:40:57.727Z","comments":true,"path":"2019/10/07/java 内存结构/","link":"","permalink":"http://tobiasll.github.io/2019/10/07/java 内存结构/","excerpt":"","text":"序言虽然Java和C++都属于一种面向对象型的语言，但是在内存管理方面却有着非常大的区别，书上用了《围城》中的：墙内的人想出去，墙外的人想进来这句话来形容这堵高墙，因为Java有着独特的内存动态分配策略和垃圾收集器等技术，导致Java开发人员不会像C/Cpp那样要去关注内存，从而把内存控制权力交给了jvm，使得一旦发生内存泄漏和溢出，如果对于jvm管理内存不熟悉的话，将会导致很难排查问题。 运行时数据区域jvm在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。 “Java 虚拟机具有一个堆，堆是运行时数据区域，所有类实例和数组的内存均从此处分配。堆是在 Java 虚拟机启动时创建的。”“在 JVM 中堆之外的内存称为非堆内存 (Non-heap memory)”。可以看出 JVM 主要管理两种类型的内存：堆和非堆。简单来说堆就是 Java 代码可及的内存，是留给开发人员使用的；非堆就是 JVM 留给 自己用的，所以方法区、JVM 内部处理或优化所需的内存 (如 JIT 编译后的代码缓存)、每个类结构 (如运行时常数池、字段和方法数据) 以及方法和构造方法 的代码都在非堆内存中。 JAVA 的 JVM 的内存可分为 3 个区：堆区（堆内和堆外）、栈 区(虚拟机栈和本地方法栈) 和方法区 (method) 程序计数器（pc寄存器）一块比较小的内存空间，可以看作当前线程所执行的字节码的行号指示器。在虚拟机规范中指pc寄存器。 当正在执行的方法为native时，这个计数器值则为空。 当该方法不是native时，就保存jvm正在执行的字节码指令的地址。 每一条jvm线程都有直接的程序计数器（线程私有）。 任意时刻，一条jvm线程只会执行一个该线程的当前方法。 保证至少可以存一个returnAddress类型的数据或本地指针的值 当前线程所执行的字节码行号指示器。 此内存区域是唯一一个在 Java 虚拟机规范中没有规定任何 OutOfMemoryError 情况的区域。 JAVA 虚拟机栈Java虚拟机栈描述的是Java方法执行的内存模型（JMM），并且每个方法执行的同时都会创建一个栈帧，因为除了栈帧的出入栈之外，Java虚拟机栈不会再受到其他因为的影响，所以栈帧可以在堆中分配。 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出 StackOverflowError 异常。 如果虚拟机栈可以动态扩展，当扩展时无法申请到足够的内存时会抛出 OutOfMemoryError 异常。 是线程私有的。 Java虚拟机也不需要保证内存的连续性。 通过 -Xss 调整线程堆栈大小，1.5 之后为 1M，之前为 256k，减少堆栈大小，可创建更多线程。 本地方法栈与Java虚拟机栈执行Java方法（字节码）服务不同，本地方法栈是jvm使用到的Native方法服务 与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 Nativa方法本质上是依赖于具体实现的 可以自由的决定使用怎样的机制来让Java程序调用本地方法 任何本地方法接口都会使用某种本地方法栈 本地方法接口拥有和jvm相同的能力，可以访问虚拟机运行时数据区、直接使用本地处理器的寄存器、直接从本地内存的堆中分配人员数量的内存… jvm规范允许本地方法栈实现成固定大小或者根据计算来动态拓展和收缩 Figure 5-13 shows a graphical depiction of a thread that invokes a native method that calls back into the virtual machine to invoke another Java method. This figure shows the full picture of what a thread can expect inside the Java Virtual Machine. A thread may spend its entire lifetime executing Java methods, working with frames on its Java stack. Or, it may jump back and forth between the Java stack and native method stacks. As depicted in Figure 5-13, a thread first invoked two Java methods, the second of which invoked a native method. This act caused the virtual machine to use a native method stack. In this figure, the native method stack is shown as a finite amount of contiguous memory space. Assume it is a C stack. The stack area used by each C-linkage function is shown in gray and bounded by a dashed line. The first C-linkage function, which was invoked as a native method, invoked another C-linkage function. The second C-linkage function invoked a Java method through the native method interface. This Java method invoked another Java method, which is the current method shown in the figure. 堆(堆内)java heap是可供各个线程共享的运行时内存区域，也是供所有类实例和数组对象分配内存的区域，存储了GC所管理的各种对象，内存泄漏最容易发生的区域 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。 基本上都采用了分代收集算法，分为新生代、老年代、其中新生代还分为Eden(80%)、From Survivor(10%)、To survivor(10%) 新生代： 程序新创建的对象都是从新生代分配内存，新生代由 Eden Space 和两块相同大小的 Survivor Space (通常又称 S0 和 S1 或 From 和 To) 构成，可通过 - Xmn 参数来指定新生代的大小，也可以通过 - XX:SurvivorRation 来调整 Eden Space 及 Survivor Space 的大小。 老年代： 用于存放经过多次新生代 GC 任然存活的对象，例如缓存对象，新建的对象也有可能直接进入老年代，主要有两种情况：①. 大对象，可通过启动参数设置 - XX:PretenureSizeThreshold=1024 (单位为字节，默认为 0) 来代表超过多大时就不在新生代分配，而是直接在老年代分配。②. 大的数组对象，切数组中无引用外部对象。 老年代所占的内存大小为 - Xmx 对应的值减去 - Xmn 对应的值。 区域 描述 Young Generation 即图中的 Eden + From Space + To Space Eden 存放新生的对象 Survivor Space 有两个，存放每次垃圾回收后存活的对象 Old Generation Tenured Generation 即图中的 Old Space Permanent Generation 主要存放应用程序中生命周期长的存活对象 堆容量可以是固定的也可以是动态拓展和收缩的，内存不需要保证连续 你可以用 JConsole 或者 Runtime.maxMemory (), Runtime.totalMemory (), Runtime.freeMemory () 来查看 Java 中堆内存的大小。 你可以使用命令 “jmap” 来获得 heap dump，用 “jhat” 来分析 heap dump。 Java 堆内存是操作系统分配给 JVM 的内存的一部分。 请使用 Profiler 和 Heap dump 分析工具来查看 Java 堆空间，可以查看给每个对象分配了多少内存。 直接内存(堆外)直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用，而且也可能导致OutOfMemoryError异常出现， 本机直接内存的分配不会受到Java堆大小的限制，但是，既然是内存，肯定还是会受到本机总内存大小以及处理器寻址空间的限制 配置虚拟机参数时不要忽略直接内存，因为会使得各个内存区域总和大于物理内存的限制，从而导致拓展时出现OOM异常 基于通道（Channel）和缓冲区（Buffer）IO方式的NIO，可以使用Native函数库直接分配堆外内存，避免在Java堆和native堆来回复制数据来提升总体的性能 不会影响到堆内内存大小 方法区方法区是可供各个线程共享的内存区域，存储了每一个类的结构信息，jvm规范中容量可以是固定的也可以是动态收缩的，并且内存不用保证有连续性 根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 JDK 7之前，使用永久代实现方法区（容易遇到内存溢出问题），JDK 7 使用Native Memory本地内存来代替永久代，JDK8使用Metaspace元数据区来实现方法区，利用元数据分配只受本地内存大小的限制（本地内存剩多少，元数据就有多大）来解决永久代的OOM问题 运行时常量池运行时常量池是class文件中每一个类或接口的常量池的运行是表示形式，存储数据的范围都比通常意义上的符号表要更广泛，都在jvm的方法区中进行分配，在加载类和接口道jvm后创建对应的运行时常量池，同时具备方法区的动态拓展和收缩 受到方法区内存的限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。 Java语言并不要求常量一定只有编译期才能产生，也就是并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的便是String类的intern()方法。 栈帧小结Java的内存结构的大致就分以上几个点，其中Java堆，是比较重要的一块，也是常见的内存溢出重灾区，GC主要区域，篇幅会比较多 参考资料《深入理解Java虚拟机》 周志明 《Java 8 虚拟机规范》","categories":[],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://tobiasll.github.io/tags/jvm/"}]},{"title":"使用frp渗透公司内网中的本机虚拟机服务器","slug":"使用frp渗透公司内网中的本机虚拟机服务器","date":"2019-09-29T02:05:11.000Z","updated":"2019-11-19T07:00:06.621Z","comments":true,"path":"2019/09/29/使用frp渗透公司内网中的本机虚拟机服务器/","link":"","permalink":"http://tobiasll.github.io/2019/09/29/使用frp渗透公司内网中的本机虚拟机服务器/","excerpt":"","text":"序言由于公司配了一条新的8G内存条，之前开虚拟机都会导致本机内存满掉，这次终于可以愉快的开虚拟机了:smirk:，虽然手上有三台服务器，搬瓦工和Google cloud 还有阿里云各一台，但是都是最低配置的，没法做集群，而且没法开多个服务，所以决定将电脑的centos虚拟机当成一台服务器，但是公司做了很多网络限制，例如网盘，网易云，bilibili等很多网站都被做了限制，以及外网根本连不进去公司的电脑，所以只能通过代理的形式，目前使用shadowsocks 全局代理形式访问被公司封禁的网站，使用frp / ngrok和 teamview 连进公司的电脑，teamview 安装Linux的会出现很多问题，而且只能进行ssh 连接，不能进行端口转发，所以这次我们使用frp来进行端口转发，外网访问内网的虚拟机的rabbitMQ服务 FRP简介 frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp 协议，为 http 和 https 应用协议提供了额外的能力，且尝试性支持了点对点穿透。 架构图 其实就是外网去访问一个带有公网ip的反向代理服务器，然后代理服务端被内网的服务所连接绑定，然后配置一些端口，告诉代理服务器，这些端口进来的请求，转发到这台内网服务的某个端口，然后将响应内容在转回给代理服务器，再由代理服务器转给外网 FRP 服务可以分配给你一个域名让你本地的 web 项目提供给外网访问， 特别适合向别人展示你本机的 web demo 以及调试一些远程的 API (比如微信公众号，企业号的开发)，还有计算资源很有限的情况，例如只有一台很低配置的不能开启多个服务的外网服务器，但是内网的计算资源却很充足，也可以frp来充分利用资源。 搭建服务首先到frp的GitHub拿到安装包 https://github.com/fatedier/frp/releases 然后复制你要安装的安装包地址，Linux 在命令行输入 1wget https://github.com/fatedier/frp/releases/download/v0.29.0/frp_0.29.0_linux_amd64.tar.gz 然后解压安装包，进入frp目录 1tar -zxvf frp_0.29.0_linux_amd64.tar.gz 需要说明的一点是frp分为服务端和客户端分别以frp开头，服务端s结尾，客户端c结尾，frps / frpc，对应的配置文件为frps.ini / frpc.ini 按照上面的架构图，需要一台服务做反向代理，而且这台服务器必须是公网的，来部署frp服务端，这里我之前想拿到公司内网电脑的外网ip，但是试了很多办法都没用，所以我用了一台阿里云来当服务端，Windows的centos虚拟机来当客户端 分辨自己路由器 IP 是真实的公网 IPtracert 追踪路由也是依赖 ICMP 回显请求和 ICMP 回显应答数据包，因此可以看作 ping 的一个扩展，它用来查看网络所经过的每一跳路由并显示路由的延迟与 ip 地址，可以用来发现出故障的网络路径。 Windows : 点击该 链接 得到自己当前的 IP 地址。 环境：Windows10— 打开一个命令提示窗口tracert 108.216.***.***(输入刚才得到的IP地址) 如果只有一跳那就说明你的路由器上面是有公网 IP 地址的，如果超过一个跳跃点那就肯定是内网 IP 地址了。 Linux/ Max OS : curl 请求 ifconfig.me 拿到ip 输入traceroute 来代替 windows的tracert 配置服务端连上外网服务器的ssh 命令行，wget获取安装压缩包，解压进去目录，vi 编辑frps.ini，注意是frps，后面是s不是c，下面的配置是最简单的情况，还有很多特殊的参数，有需要的自行去看官方文档 123# frps.ini[common]bind_port = 7000 这个端口是后期客户端要连接的端口（如果设置了防火墙，注意开放端口，把端口暴露出来，阿里云要配置安全组），然后保存，输入启动服务命令，注意这里是frps后面是s不c 1./frps -c ./frps.ini # -c 后面指定服务端配置文件 启动如果没用报错之类的，可以考虑按ctrl + C停掉服务用后台启动的方式启动服务 1nohub ./frps -c ./frps.ini &amp; 目录下会生成nohub.out 日志文件 配置客户端现在我们在内网虚拟机配置客户端，和上面一样，解压frp，配置frpc.ini 123456# frpc.ini[common]# 服务端服务器的公网ip地址server_addr = 47.107.x.x# 端口server_port = 7000 配置好要连接的代理服务器IP就可以启动了，当然这里没进行任何的端口转发配置 1./frpc -c ./frpc.ini # -c 后面指定客户端端配置文件 如果如果出错了，会报错，一般都是报连接失败，可能你的服务端没开启，导致的。 同样可以改成后台启动 1nohub frpc -c frpc.ini &amp; 外网ssh连接内网服务器下面我们配一下ssh转发，这样我们就可以使用外网的ip加上固定的端口，ssh连接上我们内网的服务器了 123456789101112131415# frpc.ini[common]server_addr = x.x.x.xserver_port = 7000#[这个里面的内容可以随意命名][secret_ssh]type = stcp# 只有 sk 一致的用户才能访问到此服务 可以删除sk = abcdefg# 127.0.0.1 或者内网iplocal_ip = 127.0.0.1 local_port = 22# 外网ssh连接内网时用的端口 这里我用6000 意思就是 ssh阿里云服务22端口# 就是连接阿里云，6000就是ssh连接内网服务器remote_port = 6000 然后启动客户端 1./frpc -c ./frpc.ini # -c 后面指定客户端端配置文件 服务端开放6000端口，使用Xshell工具或者Linux/mac 输入命令行 ssh -p 6000 root@47.107.x.x进行ssh连接，连接成功 使用22端口链接阿里云服务器 使用6000端口连接公司内网的服务器 外网访问rabbitMQ等服务首先先去docker 拉个rabbitMQ镜像下拉，然后启动/或用其他方式安装个rabbitMQ，启动服务 然后去浏览器用内网ip访问一下rabbitMQ是否能正常访问 这时用外网IP访问一下，发现是失败的，现在我们就要配一下15672的端口转发, 将下面的配置复制到客户端的frpc.ini 文件 123456789# frpc.ini[tcp1]type = tcp# 本地监听地址，内网地址均可，运行在路由器时有大用处。local_ip = 127.0.0.1# 本地监听端口local_port = 15672# 入口端口，这个端口会绑定本地的15672remote_port = 15672 然后启动客户端，外网浏览器访问服务端ip加remote_port端口 java连接mq发现报错了，拒绝连接，需要暴露amqp的5672端口 12345[tcp2]type = tcplocal_ip = 127.0.0.1local_port = 5672remote_port = 5672 阿里云记得配置安全组暴露5672和15672端口 不知道有哪些端口被使用可以使用sudo nmap -p 1-65535 localhost查看、 客户端具体配置参数 客户端可选参数 如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127&gt; # [common] 主配置标识&gt; [common]&gt; # frps服务端ip/域名&gt; server_addr = 155.254.32.55&gt; # frps服务端通讯端口，需要与服务端保持一致&gt; server_port = 7000&gt; # 认证密钥 需要与服务端保持一致&gt; token = 12345678&gt; &gt; ### 以上为必须配置，错误将无法连接服务器 ###&gt; ### 以下为可选配置 ###&gt; &gt; # 日志记录路径&gt; log_file = ./frpc.log&gt; # 日志记录级别: trace, debug, info, warn, error&gt; log_level = info&gt; # 日志保留天数&gt; log_max_days = 3&gt; &gt; &gt; # 通过代理链接服务器 ，可选http代理与sock5代理&gt; # 仅对tcp穿透有效&gt; # http_proxy = http://user:passwd@192.168.1.128:8080&gt; # http_proxy = socks5://user:passwd@192.168.1.128:1080&gt; &gt; &gt; # 通过http api设置控制frpc动作的管理地址 例如热加载配置文件。&gt; admin_addr = 127.0.0.1&gt; admin_port = 7400&gt; admin_user = admin&gt; admin_passwd = admin&gt; &gt; # 为客户端启用连接池，指定预创建连接的数量，默认为0及不启用&gt; pool_count = 5&gt; &gt; # TCP 多路复用，该配置项在服务端和客户端必须一致。默认启用&gt; tcp_mux = true&gt; &gt; # 自定义穿透名称。可自定义&gt; user = your_name&gt; &gt; # 决定第一次登录失败时是否退出程序，否则将继续尝试登陆。&gt; login_fail_exit = true&gt; &gt; # 选择用于连接服务器的通讯协议。&gt; # 可选tcp/kcp 默认tcp,kcp 使用kcp需要服务器支持。&gt; protocol = tcp&gt; &gt; # 指定DNS服务器。否则默认&gt; dns_server = 8.8.8.8&gt; &gt; # 您想要启动的代理名称，以','分割&gt; # 默认为空，表示所有代理，默认即可，此项我也没搞懂有啥用。&gt; # start = ssh,dns&gt; &gt; # 心跳包配置，默认即可，无需配置。与服务器保持一致&gt; # heartbeat_interval = 30&gt; # heartbeat_timeout = 90&gt; &gt; &gt; &gt; &gt; ### 以上为frpc连接frps的总体配置 接下来配置具体的穿透服务 ###&gt; &gt; &gt; &gt; # 每个穿透服务的名称，可以自定义。不重复即可&gt; # 本例是一个http 穿透，用于将搭建与本地http协议的站点穿透至服务器，提供公网访问。&gt; [http_demo] &gt; &gt; # 选择穿透协议类型 可选：tcp，udp，http，https，stcp，xtcp&gt; type = http&gt; &gt; # 本地监听地址，内网地址均可，运行在路由器时有大用处。&gt; local_ip = 127.0.0.1&gt; # 本地监听端口&gt; local_port = 8080&gt; # 是否启用加密，默认关闭&gt; use_encryption = true&gt; # 是否启用压缩，默认关闭&gt; use_compression = true&gt; &gt; # 通过密码保护你的 web 服务&gt; # 由于所有客户端共用一个 frps 的 http 服务端口，任何知道你的域名和 url 的人都能访问到你部署在内网的 web 服务，但是在某些场景下需要确保只有限定的用户才能访问。&gt; # frp 支持通过 HTTP Basic Auth 来保护你的 web 服务，使用户需要通过用户名和密码才能访问到你的服务。&gt; # 该功能目前仅限于 http 类型的代理，需要在 frpc 的代理配置中添加用户名和密码的设置。&gt; http_user = admin&gt; http_pwd = admin&gt; &gt; ## 自定义二级域名&gt; # 假如你的frps服务端已经配置了subdomain_host参数，并且已经将 *.&#123;subdomain_host&#125;解析到服务器，则可以直接使用subdomain参数，只需要填写子域名，无需填写完整域名&gt; # 该参数可以自定义，但是不能重复，即同一个服务端同时只能绑定一个唯一的二级域名。&gt; subdomain = demo_http &gt; &gt; # 假如服务器端未配置subdomain_host参数，则使用该参数设置绑定域名，需提前将域名解析至服务器。&gt; custom_domains = demo_http.frp02.wefinger.club&gt; &gt; # frp 支持根据请求的 URL 路径路由转发到不同的后端服务。&gt; # 通过配置文件中的 locations 字段指定一个或多个 proxy 能够匹配的 URL 前缀(目前仅支持最大前缀匹配，之后会考虑正则匹配)。例如指定 locations = /news，则所有 URL 以 /news 开头的请求都会被转发到这个服务。&gt; # 仅支持http类型。&gt; locations = /,/pic&gt; &gt; # 原来 http 请求中的 host 字段 test.yourdomain.com 转发到后端服务时会被替换为 dev.yourdomain.com&gt; # 可选配置，默认不改变数据。&gt; host_header_rewrite = example.com&gt; &gt; &gt; ## tcp 穿透示例，以穿透ssh服务为例&gt; [demo_ssh]&gt; type = tcp&gt; local_ip = 127.0.0.1&gt; local_port = 22&gt; use_encryption = true&gt; use_compression = true&gt; # 绑定远程端口。例如本例就是将本地22端口绑定至服务器2222端口，启用穿透后ssh 服务器ip的2222端口即可访问本地主机&gt; # 如果此处填写0 则服务器会随机分配一个可用端口用于此穿透服务&gt; remote_port = 2222&gt; &gt; ## udp穿透示例，以转发dns请求为例&gt; [demo_dns]&gt; type = udp&gt; local_ip = 8.8.8.8&gt; local_port = 53&gt; remote_port = 6002&gt; use_encryption = false&gt; use_compression = false&gt; 小结其实使用起来就是配置一下服务端和客户端，通过代理转发端口来达到内网渗透 引用资料frp官方文档 frpc 配置文件全解","categories":[],"tags":[{"name":"工具使用","slug":"工具使用","permalink":"http://tobiasll.github.io/tags/工具使用/"}]},{"title":"使用hexo搭建个人博客的细节","slug":"使用hexo搭建个人博客的细节","date":"2019-09-26T06:05:45.000Z","updated":"2019-11-19T06:36:59.609Z","comments":true,"path":"2019/09/26/使用hexo搭建个人博客的细节/","link":"","permalink":"http://tobiasll.github.io/2019/09/26/使用hexo搭建个人博客的细节/","excerpt":"","text":"一直都想写点技术文章，但由于鄙人不才，知识储备太少，所以工作一年都是看书和看视频等知识输入类型，并没有进行知识输出，现在决定搭建个人博客，不断学习的过程中写点东西，来当作自己的总结和分享 博客开源框架选择搭建博客有很多种方式，可以完全靠自己纯手工搭建，或采用开源的东西，前者本人觉得太折腾，所以不太适合我这种只想写点文章的个人用户，所以我选了开源静态博客框架加GitHub Page来托管等实现方案，开源框架目前比较火的有Hexo 、Jekyll、WordPress、ghost、Simple，Octopress… ## Hexo 和 Jekyll这是两种我比较了解的框架，两个都是比较主流的选择下面说一下选择原因吧！ Jekyll的底层是 Ruby，而Hexo 的底层是NodeJS，所以要求你有NodeJS环境或者Ruby，由于本人上班的电脑是Windos环境，安装Ruby感觉会比NodeJS麻烦，所以这一点我还是选了Hexo 虽然两者都是支持Markdown语法和有很多主题，但是我更喜欢Hexo的主题 之前的蚂蚁金服的sofa stack群里发现他们的sofa官网是Hexo写的，同时也期待他们开源这套主题模板，本人想用:joy: 废话不多说，下面开始安装搭建环境，hexo官网:https://hexo.io/ Github创建项目由于我们并没有后端服务器，所以我们把博客的东西都放到GitHub上，让GitHub做托管，这里由于我没有申请域名所以我还是用标准的GitHub Page ，由于GitHub有个特点就是它会用你的用户名.github.io/项目名/访问你仓库的index.html，例如：tobiasll.github.io/HappyBirthday所以我们要创建一个项目名叫 你的GitHub用户名.github.io来作为你的blog仓库，到时候如何没有买域名的小伙伴就可以直接用你的用户名.github.io不用加上项目名就可以直接访问你的博客了 新建项目首先到github创建一个项目，项目名为你的用户名.github.io 为什么图片要用红圈圈着SSH，因为后面我们可以用SSH keys 方式部署hexo提交代码，就不用每次都输入用户名和密码 安装Git既然是托管到github，那肯定要安装Git啊！Git官网:https://git-scm.com/，git的安装自行Google 安装完我们要设置ssh key ，首先进入或者在菜单里搜索 Git Bash，设置 user.name 和 user.email 配置信息： 12git config --global user.name &quot;你的GitHub用户名&quot;git config --global user.email &quot;你的GitHub注册邮箱&quot; 然后生成设置SSH密钥文件 1ssh-keygen -t rsa -C &quot;你的GitHub注册邮箱&quot; 输入命令后去C盘框生存目录的地址找到id_rsa.pub文件然后复制这个文件的密钥字符串到github 的新增ssh key中 然后到gitBash 测试一下输入 1ssh git@github.com 安装NodeJSHexo 基于 Node.js，Node.js 下载地址：Download | Node.js 下载安装包，注意安装 Node.js 会包含环境变量及 npm 的安装，安装后，检测 Node.js 是否安装成功，在命令行中输入 node -v 检测 npm 是否安装成功，在命令行中输入 npm -v : 安装Hexo先到你的想要存放的hexo数据的目录下创建一个空的文件夹，然后进去文件夹，在地址栏输入cmd进入命令行 然后输入安装hexo的命令 1npm install -g hexo-cli 安装完成输入,初始化我们的博客 1hexo init blog 这是初始化完成就会出现一个blog文件夹 然后在命令行测试hexo是否搭建成功，输入(注意如掉//后面的内容，) 123hexo n test_tobias # 注释 hexo new &quot;我的博客&quot; 新建文章hexo g # hexo generate 生成hexo s # hexo server 启动服务预览 然后在浏览器输入：http://localhost:4000，出现以下页面则说明搭建成功 推送本地hexo到github托管因为我们要做到的时让别人能通过外网访问我们的博客，上面的方式是在本机部署的方式，所以我们要把代码放到GitHub上，让github24小时托管，我们每次在本地写完文章或修改配置后部署到github上就好了 为了达到此目的，我们需要修改_config.yml配置文件，绑定我们的git地址，但是_config.yml是有两个一模一样的名子的，希望大家注意一下，别被坑到 第一个是在blog文件夹下的，是用来配置hexo站点的站点配置文件 第二个是在themes文件下的，是用来配置主题也就是页面样式的主题配置文件 那我们需要推送网站到github上，所以我们就需要配置站点的git地址，所以我们要修改blog目录下_config.yml的站点配置文件 打开config.yml文件添加 下面的配置：type、repo、brach前面一定要有两个空格，冒号：后面也要一个空格 1234deploy: type: git repo: 这里填入你之前在GitHub上创建仓库的ssh完整路径，记得加上.git branch: master 注意repo地址是ssh地址，不是https地址， 然后按保存，其实就是给 hexo d 这个命令做相应的配置，让 hexo 知道你要把 blog 部署在哪个位置，很显然，我们部署在我们 GitHub 的仓库里。最后安装 Git 部署插件，输入命令： 1npm install hexo-deployer-git --save 安装完就可以开始推送博客了 1234hexo clean # 清除缓存文件 (db.json) 和已生成的静态文件 (public)。在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。hexo g # hexo generate 生成静态文件。hexo d # hexo deploy 部署网站。 然后出现，这时你的GitHub项目也有一堆文件 然后就可以在你的浏览器输入 你的github用户名.github.io就可以访问博客了，ok，这时候如果成功出现页面则说明推送成功了，也可以正常使用，只是页面有很多参数都不是你想要的，而且很丑，所以这时候我们要去修改参数和主题，使这个博客变成真正属于你的网站 修改站点参数站点的config.yml可以修改一部分参数，例如 但是修改内容非常有限，所以这里不建议修改站点配置来达到目的，我们去修改themes下的另一个config.yml文件来达到修改样式的目的，那不喜欢这个主题的样式怎么办，这时候我们就可以换个主题，hexo是一个支持自定义主题模板的框架，同时官网也有很多开源的主题开源更换 更换主题 到官网选一个自己喜欢的主题，然后点图片进去预览，点红框的主题模板名字就可以进去模板的github了，里面都有很详细的配置和安装教程 然后就一步步按着安装就好了，然后遇到坑就自己去Google解决 archer主题启用 Algolia 搜索因为我用的模板是支持Algolia服务的，里面有个小坑，安装步骤 主题启用Algolia的链接https://github.com/fi3ework/hexo-theme-archer/wiki/%E5%90%AF%E7%94%A8-Algolia-%E6%90%9C%E7%B4%A2 其中这一段是有坑的，因为cmd打开的命令行执行hexo aligolia一直报错 加上当时上班中午没睡觉在搭博客，有点懵逼，不断在从新添加apikey和换不同的apiKey来尝试，但是都没生效，于是我就在不用set 变量了改用git bash的export了，结果一次就成功了，所以这个坑，如果大家遇到的话，注意一下 再说一个坑：Algolia 跳转到yoursite.com 点击搜索结果的时候跳转地址居然不是你的网页，跑到了http://yoursite.com/xxxx去了 解决，首先去\\blog\\node_modules\\hexo-algolia\\lib修改command.js文件 找到INDEXED_PROPERTIES这个字段 向里面添加一个path字段 1234567891011var INDEXED_PROPERTIES = [ 'title', 'date', 'updated', 'slug', 'path', 'excerpt', 'permalink', 'layout', 'image']; 然后到站点配置文件修改掉url字段值 把这个值修改为你的博客链接，然后更新下Algolia 就好了 使用Hexo其实一般正常使用就记住那几个最简单的命令，也可以上官网看看命令， 1234567hexo new [layout] &lt;title&gt;新建一篇文章。如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。特别想开启about me功能时，执行 hexo new page &quot;about&quot;在 hexo 目录下 source/about/index.md 中添加字段 layout: about（这个字段必须有且不可更改为其他）不能用 hexo n &quot;文章名&quot;hexo n 新增的文章会保存在\\hexo\\blog\\source\\_posts文件夹下，直接去哪里打开md文件编写内容保存即可hexo new page &quot;文章名&quot; 出现在\\hexo\\blog\\文章名\\aboutindex.md 1234hexo generate生成静态文件。简写 hexo g编写完文章，运行hexo g就好生存新增静态文件，然后部署到GitHub即可 123hexo deploy部署网站。简写 hexo d 1234hexo clean清除缓存文件 (db.json) 和已生成的静态文件 (public)。在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。 other 看官网，或者等更新，常用的就这几个 小结其实搭建博客基本一步步按照说明搭建，坑会很少的，而且很快就搭建起来的，关于hexo的使用遇到小坑或好用的骚操作，由于自己也是第一次用这个东西，加上鄙人不才，所以就写了一点点，后续我再不断更新博客，希望大家搭建博客都非常顺利，第一次写博客，花了我两个小时，写的非常不好，希望大家见谅，文章有错误和需要修改的地方，或者有好的建议都可以在博客判断的微信二维码或者邮箱或者GitHub issue 给我发信息，谢谢大家！ 关于绑定域名这块请看下面《GitHub+Hexo 搭建个人网站详细教程》的文章，由于我并没有操作过，以及我没有需要补充的地方，所以我就没有写这一块的内容 参考资料《GitHub+Hexo 搭建个人网站详细教程》 《Hexo 官网》","categories":[],"tags":[{"name":"工具使用","slug":"工具使用","permalink":"http://tobiasll.github.io/tags/工具使用/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-09-25T09:56:34.238Z","updated":"2019-09-25T09:56:34.239Z","comments":true,"path":"2019/09/25/hello-world/","link":"","permalink":"http://tobiasll.github.io/2019/09/25/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}